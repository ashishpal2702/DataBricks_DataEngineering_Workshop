{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4706b1a-8a72-4f05-909d-78913b79977d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "917b051d-50ed-4f00-be02-73d5084121a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\"\"\"\n",
    "GlobalShip Logistics Workshop Dataset Generator\n",
    "Creates realistic datasets for the Databricks Data Engineering Capstone Project\n",
    "\n",
    "This script generates:\n",
    "- Streaming JSON datasets (package scans, vehicle telemetry, facility events)\n",
    "- Batch Parquet datasets (customers, facilities, routes, weather)\n",
    "- Slowly changing dimension tables\n",
    "- Reference/lookup tables\n",
    "\n",
    "Usage:\n",
    "    # Local development\n",
    "    python3 data_generator.py\n",
    "    \n",
    "    # Databricks Unity Catalog Volume\n",
    "    python3 data_generator.py \"/Volumes/catalog/schema/volume_name/workshop_data\"\n",
    "    \n",
    "    # Or call from code\n",
    "    from data_generator import main\n",
    "    main(\"/Volumes/my_catalog/my_schema/my_volume/globalship_data\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a484508-23c0-4ee9-9a60-79a338366541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#pip install json faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f243c2-47a8-42c8-a97f-e9879682f0d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9840d66c-9d83-4855-ac46-ef812df18ddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import random\n",
    "import uuid\n",
    "import faker\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# Initialize Faker for realistic data generation\n",
    "fake = faker.Faker()\n",
    "fake.add_provider(faker.providers.company)\n",
    "fake.add_provider(faker.providers.address)\n",
    "\n",
    "# Vehicle makes and models for realistic data\n",
    "VEHICLE_MAKES = [\"Ford\", \"Chevrolet\", \"Mercedes-Benz\", \"Volvo\", \"Freightliner\", \"Peterbilt\", \"Kenworth\", \"Mack\", \"International\", \"Isuzu\"]\n",
    "VEHICLE_MODELS = [\"Transit\", \"Express\", \"Sprinter\", \"F-150\", \"Silverado\", \"VNL\", \"Cascadia\", \"T680\", \"Anthem\", \"NPR\"]\n",
    "\n",
    "def generate_vin():\n",
    "    \"\"\"Generate a realistic VIN number\"\"\"\n",
    "    letters = \"ABCDEFGHJKLMNPRSTUVWXYZ\"\n",
    "    numbers = \"0123456789\"\n",
    "    return ''.join([\n",
    "        random.choice(letters) for _ in range(3)\n",
    "    ]) + ''.join([\n",
    "        random.choice(numbers) for _ in range(5)\n",
    "    ]) + ''.join([\n",
    "        random.choice(letters + numbers) for _ in range(9)\n",
    "    ])\n",
    "\n",
    "def generate_license_plate():\n",
    "    \"\"\"Generate a realistic license plate\"\"\"\n",
    "    letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    numbers = \"0123456789\"\n",
    "    return ''.join([\n",
    "        random.choice(letters) for _ in range(3)\n",
    "    ]) + '-' + ''.join([\n",
    "        random.choice(numbers) for _ in range(4)\n",
    "    ])\n",
    "\n",
    "class LogisticsDataGenerator:\n",
    "    \"\"\"Generate realistic logistics datasets for workshop\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir=\"workshop_datasets\"):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        (self.output_dir / \"streaming\").mkdir(exist_ok=True)\n",
    "        (self.output_dir / \"batch\").mkdir(exist_ok=True)\n",
    "        (self.output_dir / \"reference\").mkdir(exist_ok=True)\n",
    "        \n",
    "        # Seed data for consistency\n",
    "        random.seed(42)\n",
    "        np.random.seed(42)\n",
    "        fake.seed_instance(42)\n",
    "        \n",
    "        # Business logic constants\n",
    "        self.SERVICE_TYPES = [\"STANDARD\", \"EXPRESS\", \"SAME_DAY\", \"INTERNATIONAL\"]\n",
    "        self.PACKAGE_STATUSES = [\"PICKED_UP\", \"IN_TRANSIT\", \"AT_FACILITY\", \"OUT_FOR_DELIVERY\", \"DELIVERED\", \"EXCEPTION\"]\n",
    "        self.FACILITY_TYPES = [\"HUB\", \"STATION\", \"DEPOT\", \"SORT_CENTER\", \"DELIVERY_CENTER\"]\n",
    "        self.VEHICLE_TYPES = [\"TRUCK\", \"VAN\", \"AIRCRAFT\", \"TRAIN\"]\n",
    "        self.REGIONS = [\"AMERICAS\", \"EMEA\", \"APAC\"]\n",
    "        \n",
    "        # Generate base reference data first\n",
    "        self.facilities_df = self._generate_facilities(5000)\n",
    "        self.customers_df = self._generate_customers(100000)\n",
    "        self.vehicles_df = self._generate_vehicles(180000)\n",
    "        self.routes_df = self._generate_routes(50000)\n",
    "        \n",
    "        print(f\"Initialized LogisticsDataGenerator with output directory: {self.output_dir}\")\n",
    "\n",
    "    def _generate_tracking_number(self):\n",
    "        \"\"\"Generate realistic tracking numbers\"\"\"\n",
    "        return f\"GS{random.randint(100000000000, 999999999999)}\"\n",
    "    \n",
    "    def _generate_coordinates(self, region=\"AMERICAS\"):\n",
    "        \"\"\"Generate realistic coordinates based on region\"\"\"\n",
    "        if region == \"AMERICAS\":\n",
    "            lat = random.uniform(25.0, 49.0)  # US latitude range\n",
    "            lon = random.uniform(-125.0, -66.0)  # US longitude range\n",
    "        elif region == \"EMEA\":\n",
    "            lat = random.uniform(35.0, 70.0)  # Europe latitude range\n",
    "            lon = random.uniform(-10.0, 50.0)  # Europe longitude range\n",
    "        else:  # APAC\n",
    "            lat = random.uniform(-45.0, 45.0)  # APAC latitude range\n",
    "            lon = random.uniform(95.0, 180.0)  # APAC longitude range\n",
    "        \n",
    "        return round(lat, 6), round(lon, 6)\n",
    "\n",
    "    # =================\n",
    "    # REFERENCE DATA (Slowly Changing)\n",
    "    # =================\n",
    "    \n",
    "    def _generate_facilities(self, count=5000):\n",
    "        \"\"\"Generate facilities master data - updates weekly\"\"\"\n",
    "        facilities = []\n",
    "        \n",
    "        for i in range(count):\n",
    "            region = random.choice(self.REGIONS)\n",
    "            lat, lon = self._generate_coordinates(region)\n",
    "            \n",
    "            facility = {\n",
    "                \"facility_id\": f\"FAC{str(i).zfill(6)}\",\n",
    "                \"facility_code\": f\"GS{chr(65 + i % 26)}{str(i % 1000).zfill(3)}\",\n",
    "                \"facility_name\": f\"{fake.city()} {random.choice(self.FACILITY_TYPES).title()}\",\n",
    "                \"facility_type\": random.choice(self.FACILITY_TYPES),\n",
    "                \"region\": region,\n",
    "                \"country\": fake.country(),\n",
    "                \"state_province\": fake.state(),\n",
    "                \"city\": fake.city(),\n",
    "                \"postal_code\": fake.postcode(),\n",
    "                \"street_address\": fake.street_address(),\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"timezone\": random.choice([\"UTC-8\", \"UTC-5\", \"UTC\", \"UTC+1\", \"UTC+8\"]),\n",
    "                \"capacity_packages_per_hour\": random.randint(1000, 50000),\n",
    "                \"operating_hours_start\": random.choice([\"06:00\", \"07:00\", \"08:00\"]),\n",
    "                \"operating_hours_end\": random.choice([\"18:00\", \"20:00\", \"22:00\"]),\n",
    "                \"is_active\": random.choice([True] * 95 + [False] * 5),  # 95% active\n",
    "                \"opened_date\": fake.date_between(start_date=\"-10y\", end_date=\"today\"),\n",
    "                \"last_updated\": datetime.now(timezone.utc).isoformat(),\n",
    "                \"manager_email\": fake.email(),\n",
    "                \"phone\": fake.phone_number(),\n",
    "                \"customs_facility\": random.choice([True, False]) if region in [\"AMERICAS\", \"EMEA\"] else False\n",
    "            }\n",
    "            facilities.append(facility)\n",
    "        \n",
    "        return pd.DataFrame(facilities)\n",
    "    \n",
    "    def _generate_customers(self, count=100000):\n",
    "        \"\"\"Generate customer master data - updates daily\"\"\"\n",
    "        customers = []\n",
    "        \n",
    "        for i in range(count):\n",
    "            region = random.choice(self.REGIONS)\n",
    "            lat, lon = self._generate_coordinates(region)\n",
    "            \n",
    "            # Customer segments affect shipping behavior\n",
    "            segment = random.choices(\n",
    "                [\"ENTERPRISE\", \"SMB\", \"CONSUMER\"], \n",
    "                weights=[20, 30, 50]\n",
    "            )[0]\n",
    "            \n",
    "            customer = {\n",
    "                \"customer_id\": f\"CUST{str(i).zfill(8)}\",\n",
    "                \"customer_type\": segment,\n",
    "                \"company_name\": fake.company() if segment != \"CONSUMER\" else None,\n",
    "                \"first_name\": fake.first_name(),\n",
    "                \"last_name\": fake.last_name(),\n",
    "                \"email\": fake.email(),\n",
    "                \"phone\": fake.phone_number(),\n",
    "                \"region\": region,\n",
    "                \"country\": fake.country(),\n",
    "                \"state_province\": fake.state(),\n",
    "                \"city\": fake.city(),\n",
    "                \"postal_code\": fake.postcode(),\n",
    "                \"street_address\": fake.street_address(),\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"account_created_date\": fake.date_between(start_date=\"-5y\", end_date=\"today\"),\n",
    "                \"last_order_date\": fake.date_between(start_date=\"-1y\", end_date=\"today\"),\n",
    "                \"total_lifetime_value\": round(random.uniform(100, 50000), 2),\n",
    "                \"avg_monthly_shipments\": random.randint(1, 500) if segment == \"ENTERPRISE\" else random.randint(1, 50),\n",
    "                \"preferred_service\": random.choice(self.SERVICE_TYPES),\n",
    "                \"credit_limit\": round(random.uniform(1000, 100000), 2),\n",
    "                \"payment_terms\": random.choice([\"NET_30\", \"NET_15\", \"PREPAID\", \"COD\"]),\n",
    "                \"is_active\": random.choice([True] * 90 + [False] * 10),\n",
    "                \"last_updated\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "            customers.append(customer)\n",
    "        \n",
    "        return pd.DataFrame(customers)\n",
    "    \n",
    "    def _generate_vehicles(self, count=180000):\n",
    "        \"\"\"Generate vehicle fleet data - updates when maintenance occurs\"\"\"\n",
    "        vehicles = []\n",
    "        \n",
    "        for i in range(count):\n",
    "            vehicle_type = random.choice(self.VEHICLE_TYPES)\n",
    "            \n",
    "            vehicle = {\n",
    "                \"vehicle_id\": f\"VEH{str(i).zfill(8)}\",\n",
    "                \"vehicle_number\": f\"GS{str(i).zfill(6)}\",\n",
    "                \"vehicle_type\": vehicle_type,\n",
    "                \"make\": random.choice(VEHICLE_MAKES) if vehicle_type in [\"TRUCK\", \"VAN\"] else random.choice([\"Boeing\", \"Airbus\", \"Freight Train\"]),\n",
    "                \"model\": random.choice(VEHICLE_MODELS) if vehicle_type in [\"TRUCK\", \"VAN\"] else f\"Model-{random.randint(100, 999)}\",\n",
    "                \"year\": random.randint(2015, 2024),\n",
    "                \"vin_number\": generate_vin() if vehicle_type in [\"TRUCK\", \"VAN\"] else f\"AIR{random.randint(100000, 999999)}\",\n",
    "                \"license_plate\": generate_license_plate() if vehicle_type in [\"TRUCK\", \"VAN\"] else None,\n",
    "                \"region\": random.choice(self.REGIONS),\n",
    "                \"home_facility_code\": random.choice(self.facilities_df[\"facility_code\"].tolist()),\n",
    "                \"capacity_weight_kg\": random.randint(500, 15000) if vehicle_type == \"VAN\" else random.randint(5000, 80000),\n",
    "                \"capacity_volume_m3\": random.randint(10, 100),\n",
    "                \"fuel_type\": random.choice([\"DIESEL\", \"GASOLINE\", \"ELECTRIC\", \"HYBRID\"]),\n",
    "                \"current_mileage_km\": random.randint(10000, 500000),\n",
    "                \"last_maintenance_date\": fake.date_between(start_date=\"-6m\", end_date=\"today\"),\n",
    "                \"last_maintenance_mileage\": random.randint(8000, 480000),\n",
    "                \"next_maintenance_due_km\": random.randint(520000, 600000),\n",
    "                \"gps_device_id\": f\"GPS{str(i).zfill(8)}\",\n",
    "                \"telematics_device_id\": f\"TEL{str(i).zfill(8)}\",\n",
    "                \"is_active\": random.choice([True] * 85 + [False] * 15),  # 85% active (rest in maintenance)\n",
    "                \"driver_id\": f\"DRV{random.randint(1, 200000)}\",\n",
    "                \"insurance_policy_number\": f\"INS{random.randint(1000000, 9999999)}\",\n",
    "                \"registration_expires\": fake.date_between(start_date=\"today\", end_date=\"+2y\"),\n",
    "                \"last_updated\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "            vehicles.append(vehicle)\n",
    "        \n",
    "        return pd.DataFrame(vehicles)\n",
    "    \n",
    "    def _generate_routes(self, count=50000):\n",
    "        \"\"\"Generate route master data - updates based on optimization\"\"\"\n",
    "        routes = []\n",
    "        \n",
    "        facilities = self.facilities_df.to_dict('records')\n",
    "        \n",
    "        for i in range(count):\n",
    "            origin = random.choice(facilities)\n",
    "            destination = random.choice(facilities)\n",
    "            \n",
    "            # Ensure origin != destination\n",
    "            while destination[\"facility_id\"] == origin[\"facility_id\"]:\n",
    "                destination = random.choice(facilities)\n",
    "            \n",
    "            # Calculate approximate distance (simplified)\n",
    "            distance_km = random.randint(50, 2000)\n",
    "            \n",
    "            route = {\n",
    "                \"route_id\": f\"RTE{str(i).zfill(8)}\",\n",
    "                \"origin_facility_id\": origin[\"facility_id\"],\n",
    "                \"origin_facility_code\": origin[\"facility_code\"],\n",
    "                \"destination_facility_id\": destination[\"facility_id\"], \n",
    "                \"destination_facility_code\": destination[\"facility_code\"],\n",
    "                \"distance_km\": distance_km,\n",
    "                \"estimated_duration_hours\": round(distance_km / random.randint(60, 120), 2),\n",
    "                \"route_type\": random.choice([\"GROUND\", \"AIR\", \"RAIL\", \"INTERMODAL\"]),\n",
    "                \"is_active\": random.choice([True] * 90 + [False] * 10),\n",
    "                \"average_cost_per_km\": round(random.uniform(0.5, 2.5), 2),\n",
    "                \"carbon_footprint_kg_co2_per_km\": round(random.uniform(0.1, 1.2), 3),\n",
    "                \"last_optimization_date\": fake.date_between(start_date=\"-30d\", end_date=\"today\"),\n",
    "                \"created_date\": fake.date_between(start_date=\"-2y\", end_date=\"today\"),\n",
    "                \"last_updated\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "            routes.append(route)\n",
    "        \n",
    "        return pd.DataFrame(routes)\n",
    "\n",
    "    # =================\n",
    "    # STREAMING DATA GENERATORS\n",
    "    # =================\n",
    "    \n",
    "    def generate_package_scans_stream(self, duration_minutes=60, events_per_second=100):\n",
    "        \"\"\"Generate streaming package scan events\"\"\"\n",
    "        print(f\"Generating package scan stream for {duration_minutes} minutes at {events_per_second} events/second...\")\n",
    "        \n",
    "        output_file = self.output_dir / \"streaming\" / \"package_scans.jsonl\"\n",
    "        facilities = self.facilities_df.to_dict('records')\n",
    "        \n",
    "        start_time = datetime.now(timezone.utc)\n",
    "        end_time = start_time + timedelta(minutes=duration_minutes)\n",
    "        \n",
    "        # Track packages for realistic journey progression\n",
    "        active_packages = {}\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            event_counter = 0\n",
    "            \n",
    "            while datetime.now(timezone.utc) < end_time:\n",
    "                timestamp = datetime.now(timezone.utc)\n",
    "                \n",
    "                for _ in range(events_per_second):\n",
    "                    # Decide if this is a new package or existing package progression\n",
    "                    if random.random() < 0.1 or not active_packages:  # 10% new packages\n",
    "                        tracking_number = self._generate_tracking_number()\n",
    "                        status = \"PICKED_UP\"\n",
    "                        facility = random.choice(facilities)\n",
    "                        \n",
    "                        # Initialize package journey\n",
    "                        active_packages[tracking_number] = {\n",
    "                            \"current_status\": status,\n",
    "                            \"current_facility\": facility,\n",
    "                            \"service_type\": random.choice(self.SERVICE_TYPES),\n",
    "                            \"journey_stage\": 0\n",
    "                        }\n",
    "                    else:\n",
    "                        # Progress existing package\n",
    "                        tracking_number = random.choice(list(active_packages.keys()))\n",
    "                        package_info = active_packages[tracking_number]\n",
    "                        \n",
    "                        # Progress through journey stages\n",
    "                        journey_stages = [\"PICKED_UP\", \"IN_TRANSIT\", \"AT_FACILITY\", \"OUT_FOR_DELIVERY\", \"DELIVERED\"]\n",
    "                        current_stage = package_info[\"journey_stage\"]\n",
    "                        \n",
    "                        if current_stage < len(journey_stages) - 1:\n",
    "                            if random.random() < 0.3:  # 30% chance to progress\n",
    "                                package_info[\"journey_stage\"] += 1\n",
    "                                status = journey_stages[package_info[\"journey_stage\"]]\n",
    "                                package_info[\"current_status\"] = status\n",
    "                                \n",
    "                                # Change facility for some status changes\n",
    "                                if status in [\"IN_TRANSIT\", \"AT_FACILITY\"]:\n",
    "                                    package_info[\"current_facility\"] = random.choice(facilities)\n",
    "                            else:\n",
    "                                status = package_info[\"current_status\"]\n",
    "                        else:\n",
    "                            status = \"DELIVERED\"\n",
    "                            # Remove delivered packages occasionally\n",
    "                            if random.random() < 0.1:\n",
    "                                del active_packages[tracking_number]\n",
    "                                continue\n",
    "                        \n",
    "                        facility = package_info[\"current_facility\"]\n",
    "                    \n",
    "                    # Add some exceptions\n",
    "                    if random.random() < 0.05:  # 5% exception rate\n",
    "                        status = \"EXCEPTION\"\n",
    "                        exception_type = random.choice([\"DAMAGED\", \"LOST\", \"DELAYED\", \"ADDRESS_ISSUE\", \"WEATHER\"])\n",
    "                    else:\n",
    "                        exception_type = None\n",
    "                    \n",
    "                    # Generate scan event\n",
    "                    scan_event = {\n",
    "                        \"event_id\": str(uuid.uuid4()),\n",
    "                        \"tracking_number\": tracking_number,\n",
    "                        \"scan_event\": status,\n",
    "                        \"facility_id\": facility[\"facility_id\"],\n",
    "                        \"facility_code\": facility[\"facility_code\"],\n",
    "                        \"facility_name\": facility[\"facility_name\"],\n",
    "                        \"latitude\": facility[\"latitude\"],\n",
    "                        \"longitude\": facility[\"longitude\"],\n",
    "                        \"scan_timestamp\": timestamp.isoformat(),\n",
    "                        \"scanner_id\": f\"SCN{random.randint(1000, 9999)}\",\n",
    "                        \"employee_id\": f\"EMP{random.randint(10000, 99999)}\",\n",
    "                        \"vehicle_id\": f\"VEH{random.randint(10000000, 99999999)}\" if status in [\"IN_TRANSIT\", \"OUT_FOR_DELIVERY\"] else None,\n",
    "                        \"service_type\": active_packages.get(tracking_number, {}).get(\"service_type\", random.choice(self.SERVICE_TYPES)),\n",
    "                        \"package_weight_kg\": round(random.uniform(0.1, 50.0), 2),\n",
    "                        \"package_dimensions\": {\n",
    "                            \"length_cm\": random.randint(10, 100),\n",
    "                            \"width_cm\": random.randint(10, 100), \n",
    "                            \"height_cm\": random.randint(5, 50)\n",
    "                        },\n",
    "                        \"exception_type\": exception_type,\n",
    "                        \"exception_description\": fake.sentence() if exception_type else None,\n",
    "                        \"temperature_celsius\": round(random.uniform(-20, 40), 1),\n",
    "                        \"humidity_percent\": random.randint(30, 90),\n",
    "                        \"handling_instructions\": random.choice([None, \"FRAGILE\", \"PERISHABLE\", \"HAZMAT\", \"SIGNATURE_REQUIRED\"]),\n",
    "                        \"customs_cleared\": random.choice([True, False, None]),\n",
    "                        \"event_source\": \"HANDHELD_SCANNER\",\n",
    "                        \"data_quality_score\": round(random.uniform(0.85, 1.0), 3)\n",
    "                    }\n",
    "                    \n",
    "                    f.write(json.dumps(scan_event) + '\\n')\n",
    "                    event_counter += 1\n",
    "                \n",
    "                # Sleep to maintain event rate\n",
    "                time.sleep(1)\n",
    "                \n",
    "                if event_counter % 10000 == 0:\n",
    "                    print(f\"Generated {event_counter:,} package scan events...\")\n",
    "        \n",
    "        print(f\"Package scan stream generation complete. Generated {event_counter:,} events.\")\n",
    "        return output_file\n",
    "    \n",
    "    def generate_vehicle_telemetry_stream(self, duration_minutes=60, events_per_second=50):\n",
    "        \"\"\"Generate streaming vehicle telemetry data\"\"\"\n",
    "        print(f\"Generating vehicle telemetry stream for {duration_minutes} minutes at {events_per_second} events/second...\")\n",
    "        \n",
    "        output_file = self.output_dir / \"streaming\" / \"vehicle_telemetry.jsonl\"\n",
    "        vehicles = self.vehicles_df.to_dict('records')\n",
    "        \n",
    "        start_time = datetime.now(timezone.utc)\n",
    "        end_time = start_time + timedelta(minutes=duration_minutes)\n",
    "        \n",
    "        # Track vehicle states for realistic progression\n",
    "        vehicle_states = {}\n",
    "        for vehicle in random.sample(vehicles, min(1000, len(vehicles))):  # Track subset for demo\n",
    "            lat, lon = self._generate_coordinates(vehicle[\"region\"])\n",
    "            vehicle_states[vehicle[\"vehicle_id\"]] = {\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"speed_kmh\": 0,\n",
    "                \"heading\": random.randint(0, 359),\n",
    "                \"is_moving\": False\n",
    "            }\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            event_counter = 0\n",
    "            \n",
    "            while datetime.now(timezone.utc) < end_time:\n",
    "                timestamp = datetime.now(timezone.utc)\n",
    "                \n",
    "                for _ in range(events_per_second):\n",
    "                    vehicle_id = random.choice(list(vehicle_states.keys()))\n",
    "                    vehicle = next(v for v in vehicles if v[\"vehicle_id\"] == vehicle_id)\n",
    "                    state = vehicle_states[vehicle_id]\n",
    "                    \n",
    "                    # Simulate realistic movement\n",
    "                    if random.random() < 0.1:  # 10% chance to change movement state\n",
    "                        state[\"is_moving\"] = not state[\"is_moving\"]\n",
    "                    \n",
    "                    if state[\"is_moving\"]:\n",
    "                        # Update position (simplified movement)\n",
    "                        state[\"latitude\"] += random.uniform(-0.001, 0.001)\n",
    "                        state[\"longitude\"] += random.uniform(-0.001, 0.001)\n",
    "                        state[\"speed_kmh\"] = random.randint(30, 90)\n",
    "                        state[\"heading\"] += random.randint(-10, 10) % 360\n",
    "                    else:\n",
    "                        state[\"speed_kmh\"] = 0\n",
    "                    \n",
    "                    # Generate telemetry event\n",
    "                    telemetry_event = {\n",
    "                        \"event_id\": str(uuid.uuid4()),\n",
    "                        \"vehicle_id\": vehicle_id,\n",
    "                        \"vehicle_number\": vehicle[\"vehicle_number\"],\n",
    "                        \"timestamp\": timestamp.isoformat(),\n",
    "                        \"location\": {\n",
    "                            \"latitude\": round(state[\"latitude\"], 6),\n",
    "                            \"longitude\": round(state[\"longitude\"], 6),\n",
    "                            \"altitude_m\": random.randint(0, 2000),\n",
    "                            \"accuracy_m\": random.randint(1, 10)\n",
    "                        },\n",
    "                        \"motion\": {\n",
    "                            \"speed_kmh\": state[\"speed_kmh\"],\n",
    "                            \"heading_degrees\": state[\"heading\"],\n",
    "                            \"acceleration_ms2\": round(random.uniform(-2, 2), 2),\n",
    "                            \"is_moving\": state[\"is_moving\"]\n",
    "                        },\n",
    "                        \"engine\": {\n",
    "                            \"rpm\": random.randint(800, 4000) if state[\"is_moving\"] else random.randint(600, 1000),\n",
    "                            \"engine_load_percent\": random.randint(10, 90) if state[\"is_moving\"] else random.randint(5, 20),\n",
    "                            \"coolant_temp_celsius\": random.randint(80, 105),\n",
    "                            \"oil_pressure_kpa\": random.randint(200, 400),\n",
    "                            \"fuel_level_percent\": random.randint(10, 100)\n",
    "                        },\n",
    "                        \"environmental\": {\n",
    "                            \"external_temp_celsius\": round(random.uniform(-20, 40), 1),\n",
    "                            \"cargo_temp_celsius\": round(random.uniform(-10, 35), 1) if vehicle[\"vehicle_type\"] in [\"TRUCK\", \"VAN\"] else None,\n",
    "                            \"humidity_percent\": random.randint(30, 90)\n",
    "                        },\n",
    "                        \"vehicle_health\": {\n",
    "                            \"odometer_km\": vehicle[\"current_mileage_km\"] + random.randint(0, 100),\n",
    "                            \"battery_voltage\": round(random.uniform(12.0, 14.5), 1),\n",
    "                            \"tire_pressure_kpa\": [random.randint(200, 250) for _ in range(4)],\n",
    "                            \"brake_wear_percent\": random.randint(20, 100),\n",
    "                            \"engine_hours\": random.randint(5000, 20000)\n",
    "                        },\n",
    "                        \"driver\": {\n",
    "                            \"driver_id\": vehicle[\"driver_id\"],\n",
    "                            \"driving_score\": random.randint(70, 100),\n",
    "                            \"harsh_braking_events\": random.randint(0, 3),\n",
    "                            \"harsh_acceleration_events\": random.randint(0, 2),\n",
    "                            \"speeding_events\": random.randint(0, 1),\n",
    "                            \"hours_driven_today\": round(random.uniform(0, 10), 1)\n",
    "                        },\n",
    "                        \"alerts\": {\n",
    "                            \"maintenance_due\": vehicle[\"current_mileage_km\"] > vehicle[\"next_maintenance_due_km\"],\n",
    "                            \"low_fuel\": random.random() < 0.05,  # 5% chance\n",
    "                            \"engine_warning\": random.random() < 0.02,  # 2% chance\n",
    "                            \"speeding\": state[\"speed_kmh\"] > 80 and random.random() < 0.1\n",
    "                        },\n",
    "                        \"data_source\": \"TELEMATICS_DEVICE\",\n",
    "                        \"device_id\": vehicle[\"telematics_device_id\"],\n",
    "                        \"signal_strength\": random.randint(1, 5),\n",
    "                        \"data_quality_score\": round(random.uniform(0.90, 1.0), 3)\n",
    "                    }\n",
    "                    \n",
    "                    f.write(json.dumps(telemetry_event) + '\\n')\n",
    "                    event_counter += 1\n",
    "                \n",
    "                # Sleep to maintain event rate\n",
    "                time.sleep(1)\n",
    "                \n",
    "                if event_counter % 5000 == 0:\n",
    "                    print(f\"Generated {event_counter:,} vehicle telemetry events...\")\n",
    "        \n",
    "        print(f\"Vehicle telemetry stream generation complete. Generated {event_counter:,} events.\")\n",
    "        return output_file\n",
    "    \n",
    "    def generate_facility_events_stream(self, duration_minutes=60, events_per_second=30):\n",
    "        \"\"\"Generate streaming facility operational events\"\"\"\n",
    "        print(f\"Generating facility events stream for {duration_minutes} minutes at {events_per_second} events/second...\")\n",
    "        \n",
    "        output_file = self.output_dir / \"streaming\" / \"facility_events.jsonl\"\n",
    "        facilities = self.facilities_df.to_dict('records')\n",
    "        \n",
    "        start_time = datetime.now(timezone.utc)\n",
    "        end_time = start_time + timedelta(minutes=duration_minutes)\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            event_counter = 0\n",
    "            \n",
    "            while datetime.now(timezone.utc) < end_time:\n",
    "                timestamp = datetime.now(timezone.utc)\n",
    "                \n",
    "                for _ in range(events_per_second):\n",
    "                    facility = random.choice(facilities)\n",
    "                    \n",
    "                    event_types = [\n",
    "                        \"CONVEYOR_STATUS\", \"SECURITY_ALERT\", \"TEMPERATURE_READING\", \n",
    "                        \"CAPACITY_UPDATE\", \"EQUIPMENT_STATUS\", \"POWER_CONSUMPTION\",\n",
    "                        \"PERSONNEL_COUNT\", \"VEHICLE_DOCK\", \"MAINTENANCE_EVENT\"\n",
    "                    ]\n",
    "                    \n",
    "                    event_type = random.choice(event_types)\n",
    "                    \n",
    "                    # Generate event-specific data\n",
    "                    event_data = {\n",
    "                        \"event_id\": str(uuid.uuid4()),\n",
    "                        \"facility_id\": facility[\"facility_id\"],\n",
    "                        \"facility_code\": facility[\"facility_code\"],\n",
    "                        \"facility_type\": facility[\"facility_type\"],\n",
    "                        \"timestamp\": timestamp.isoformat(),\n",
    "                        \"event_type\": event_type,\n",
    "                        \"region\": facility[\"region\"]\n",
    "                    }\n",
    "                    \n",
    "                    if event_type == \"CONVEYOR_STATUS\":\n",
    "                        event_data.update({\n",
    "                            \"conveyor_id\": f\"CNV{random.randint(100, 999)}\",\n",
    "                            \"status\": random.choice([\"RUNNING\", \"STOPPED\", \"MAINTENANCE\", \"ERROR\"]),\n",
    "                            \"speed_mpm\": random.randint(10, 100),\n",
    "                            \"packages_per_minute\": random.randint(50, 500),\n",
    "                            \"jam_detected\": random.random() < 0.05\n",
    "                        })\n",
    "                    \n",
    "                    elif event_type == \"TEMPERATURE_READING\":\n",
    "                        event_data.update({\n",
    "                            \"sensor_id\": f\"TEMP{random.randint(1000, 9999)}\",\n",
    "                            \"zone\": random.choice([\"WAREHOUSE\", \"OFFICE\", \"LOADING_DOCK\", \"COLD_STORAGE\"]),\n",
    "                            \"temperature_celsius\": round(random.uniform(-10, 35), 1),\n",
    "                            \"humidity_percent\": random.randint(30, 90),\n",
    "                            \"alert_triggered\": random.random() < 0.1\n",
    "                        })\n",
    "                    \n",
    "                    elif event_type == \"CAPACITY_UPDATE\":\n",
    "                        event_data.update({\n",
    "                            \"current_capacity_percent\": random.randint(30, 95),\n",
    "                            \"packages_in_facility\": random.randint(1000, 50000),\n",
    "                            \"inbound_packages_today\": random.randint(5000, 100000),\n",
    "                            \"outbound_packages_today\": random.randint(4000, 95000),\n",
    "                            \"peak_capacity_reached\": random.random() < 0.15\n",
    "                        })\n",
    "                    \n",
    "                    elif event_type == \"SECURITY_ALERT\":\n",
    "                        event_data.update({\n",
    "                            \"alert_level\": random.choice([\"LOW\", \"MEDIUM\", \"HIGH\", \"CRITICAL\"]),\n",
    "                            \"alert_type\": random.choice([\"UNAUTHORIZED_ACCESS\", \"PACKAGE_TAMPERING\", \"PERIMETER_BREACH\", \"SYSTEM_INTRUSION\"]),\n",
    "                            \"camera_id\": f\"CAM{random.randint(100, 999)}\",\n",
    "                            \"response_required\": random.random() < 0.3,\n",
    "                            \"description\": fake.sentence()\n",
    "                        })\n",
    "                    \n",
    "                    elif event_type == \"VEHICLE_DOCK\":\n",
    "                        event_data.update({\n",
    "                            \"dock_id\": f\"DOCK{random.randint(10, 99)}\",\n",
    "                            \"vehicle_id\": f\"VEH{random.randint(10000000, 99999999)}\",\n",
    "                            \"action\": random.choice([\"ARRIVED\", \"DEPARTED\", \"LOADING\", \"UNLOADING\"]),\n",
    "                            \"packages_loaded\": random.randint(0, 500) if random.choice([True, False]) else 0,\n",
    "                            \"packages_unloaded\": random.randint(0, 800) if random.choice([True, False]) else 0,\n",
    "                            \"dock_utilization_percent\": random.randint(40, 100)\n",
    "                        })\n",
    "                    \n",
    "                    f.write(json.dumps(event_data) + '\\n')\n",
    "                    event_counter += 1\n",
    "                \n",
    "                # Sleep to maintain event rate\n",
    "                time.sleep(1)\n",
    "                \n",
    "                if event_counter % 2000 == 0:\n",
    "                    print(f\"Generated {event_counter:,} facility events...\")\n",
    "        \n",
    "        print(f\"Facility events stream generation complete. Generated {event_counter:,} events.\")\n",
    "        return output_file\n",
    "\n",
    "    # =================\n",
    "    # BATCH DATA GENERATORS\n",
    "    # =================\n",
    "    \n",
    "    def generate_historical_packages(self, count=1000000):\n",
    "        \"\"\"Generate historical package data for training ML models\"\"\"\n",
    "        print(f\"Generating {count:,} historical packages...\")\n",
    "        \n",
    "        packages = []\n",
    "        facilities = self.facilities_df.to_dict('records')\n",
    "        customers = self.customers_df.to_dict('records')\n",
    "        \n",
    "        for i in range(count):\n",
    "            origin = random.choice(facilities)\n",
    "            destination = random.choice(facilities)\n",
    "            customer = random.choice(customers)\n",
    "            \n",
    "            # Ensure different origin/destination\n",
    "            while destination[\"facility_id\"] == origin[\"facility_id\"]:\n",
    "                destination = random.choice(facilities)\n",
    "            \n",
    "            ship_date = fake.date_between(start_date=\"-2y\", end_date=\"-1d\")\n",
    "            service_type = random.choice(self.SERVICE_TYPES)\n",
    "            \n",
    "            # Calculate delivery based on service type and distance\n",
    "            if service_type == \"SAME_DAY\":\n",
    "                delivery_days = 1\n",
    "            elif service_type == \"EXPRESS\":\n",
    "                delivery_days = random.randint(1, 2)\n",
    "            elif service_type == \"STANDARD\":\n",
    "                delivery_days = random.randint(2, 5)\n",
    "            else:  # INTERNATIONAL\n",
    "                delivery_days = random.randint(5, 14)\n",
    "            \n",
    "            # Add realistic delays\n",
    "            if random.random() < 0.15:  # 15% delay rate\n",
    "                delivery_days += random.randint(1, 3)\n",
    "            \n",
    "            actual_delivery_date = ship_date + timedelta(days=delivery_days)\n",
    "            \n",
    "            package = {\n",
    "                \"package_id\": f\"PKG{str(i).zfill(10)}\",\n",
    "                \"tracking_number\": self._generate_tracking_number(),\n",
    "                \"customer_id\": customer[\"customer_id\"],\n",
    "                \"service_type\": service_type,\n",
    "                \"ship_date\": ship_date.isoformat(),\n",
    "                \"promised_delivery_date\": (ship_date + timedelta(days=delivery_days - (1 if random.random() < 0.15 else 0))).isoformat(),\n",
    "                \"actual_delivery_date\": actual_delivery_date.isoformat(),\n",
    "                \"origin_facility_id\": origin[\"facility_id\"],\n",
    "                \"origin_facility_code\": origin[\"facility_code\"],\n",
    "                \"destination_facility_id\": destination[\"facility_id\"],\n",
    "                \"destination_facility_code\": destination[\"facility_code\"],\n",
    "                \"origin_address\": {\n",
    "                    \"street\": fake.street_address(),\n",
    "                    \"city\": origin[\"city\"],\n",
    "                    \"state\": origin[\"state_province\"],\n",
    "                    \"postal_code\": fake.postcode(),\n",
    "                    \"country\": origin[\"country\"],\n",
    "                    \"latitude\": origin[\"latitude\"],\n",
    "                    \"longitude\": origin[\"longitude\"]\n",
    "                },\n",
    "                \"destination_address\": {\n",
    "                    \"street\": fake.street_address(),\n",
    "                    \"city\": destination[\"city\"],\n",
    "                    \"state\": destination[\"state_province\"],\n",
    "                    \"postal_code\": fake.postcode(),\n",
    "                    \"country\": destination[\"country\"],\n",
    "                    \"latitude\": destination[\"latitude\"],\n",
    "                    \"longitude\": destination[\"longitude\"]\n",
    "                },\n",
    "                \"package_details\": {\n",
    "                    \"weight_kg\": round(random.uniform(0.1, 50.0), 2),\n",
    "                    \"dimensions_cm\": {\n",
    "                        \"length\": random.randint(10, 100),\n",
    "                        \"width\": random.randint(10, 100),\n",
    "                        \"height\": random.randint(5, 50)\n",
    "                    },\n",
    "                    \"declared_value\": round(random.uniform(10, 5000), 2),\n",
    "                    \"insurance_value\": round(random.uniform(0, 1000), 2),\n",
    "                    \"contents_description\": fake.catch_phrase(),\n",
    "                    \"special_handling\": random.choice([None, \"FRAGILE\", \"PERISHABLE\", \"HAZMAT\", \"HIGH_VALUE\"])\n",
    "                },\n",
    "                \"shipping_cost\": round(random.uniform(5.99, 299.99), 2),\n",
    "                \"fuel_surcharge\": round(random.uniform(0.50, 15.00), 2),\n",
    "                \"taxes_fees\": round(random.uniform(0, 25.00), 2),\n",
    "                \"total_revenue\": 0,  # Will calculate\n",
    "                \"delivery_status\": random.choices(\n",
    "                    [\"DELIVERED\", \"DELIVERED_LATE\", \"DAMAGED\", \"LOST\", \"RETURNED\"], \n",
    "                    weights=[75, 15, 5, 2, 3]\n",
    "                )[0],\n",
    "                \"delivery_attempts\": random.randint(1, 4),\n",
    "                \"signature_required\": random.choice([True, False]),\n",
    "                \"signature_obtained\": random.choice([True, False]),\n",
    "                \"weather_delay\": random.choice([True, False]) if random.random() < 0.1 else False,\n",
    "                \"customs_delay\": random.choice([True, False]) if service_type == \"INTERNATIONAL\" and random.random() < 0.2 else False,\n",
    "                \"distance_km\": random.randint(50, 5000),\n",
    "                \"carbon_footprint_kg\": round(random.uniform(0.5, 25.0), 3),\n",
    "                \"created_timestamp\": ship_date.isoformat(),\n",
    "                \"last_updated\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "            \n",
    "            # Calculate total revenue\n",
    "            package[\"total_revenue\"] = (\n",
    "                package[\"shipping_cost\"] + \n",
    "                package[\"fuel_surcharge\"] + \n",
    "                package[\"taxes_fees\"]\n",
    "            )\n",
    "            \n",
    "            packages.append(package)\n",
    "            \n",
    "            if i % 50000 == 0 and i > 0:\n",
    "                print(f\"Generated {i:,} historical packages...\")\n",
    "        \n",
    "        df = pd.DataFrame(packages)\n",
    "        output_file = self.output_dir / \"batch\" / \"historical_packages.parquet\"\n",
    "        df.to_parquet(output_file, index=False)\n",
    "        print(f\"Historical packages saved to {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    def generate_weather_data(self, days=365):\n",
    "        \"\"\"Generate weather data for logistics planning\"\"\"\n",
    "        print(f\"Generating weather data for {days} days...\")\n",
    "        \n",
    "        weather_records = []\n",
    "        facilities = self.facilities_df.to_dict('records')\n",
    "        \n",
    "        for facility in facilities:\n",
    "            for day_offset in range(days):\n",
    "                date = datetime.now().date() - timedelta(days=days-day_offset)\n",
    "                \n",
    "                # Generate realistic weather based on region and season\n",
    "                season_factor = np.sin(2 * np.pi * day_offset / 365)  # Seasonal variation\n",
    "                \n",
    "                if facility[\"region\"] == \"AMERICAS\":\n",
    "                    base_temp = 15 + 10 * season_factor + random.uniform(-5, 5)\n",
    "                elif facility[\"region\"] == \"EMEA\":\n",
    "                    base_temp = 10 + 8 * season_factor + random.uniform(-4, 4)\n",
    "                else:  # APAC\n",
    "                    base_temp = 25 + 5 * season_factor + random.uniform(-3, 3)\n",
    "                \n",
    "                weather_record = {\n",
    "                    \"facility_id\": facility[\"facility_id\"],\n",
    "                    \"facility_code\": facility[\"facility_code\"],\n",
    "                    \"date\": date.isoformat(),\n",
    "                    \"temperature_celsius\": {\n",
    "                        \"min\": round(base_temp - random.uniform(2, 8), 1),\n",
    "                        \"max\": round(base_temp + random.uniform(2, 8), 1),\n",
    "                        \"avg\": round(base_temp, 1)\n",
    "                    },\n",
    "                    \"humidity_percent\": random.randint(30, 90),\n",
    "                    \"precipitation_mm\": round(np.random.exponential(2) if random.random() < 0.3 else 0, 1),\n",
    "                    \"wind_speed_kmh\": round(random.uniform(5, 40), 1),\n",
    "                    \"wind_direction_degrees\": random.randint(0, 359),\n",
    "                    \"pressure_hpa\": random.randint(980, 1030),\n",
    "                    \"visibility_km\": round(random.uniform(5, 50), 1),\n",
    "                    \"uv_index\": random.randint(1, 11),\n",
    "                    \"weather_conditions\": random.choices(\n",
    "                        [\"CLEAR\", \"PARTLY_CLOUDY\", \"CLOUDY\", \"RAIN\", \"SNOW\", \"FOG\", \"STORM\"],\n",
    "                        weights=[30, 25, 20, 15, 5, 3, 2]\n",
    "                    )[0],\n",
    "                    \"severe_weather_alert\": random.random() < 0.05,  # 5% chance\n",
    "                    \"flight_delays_expected\": random.random() < 0.1,  # 10% chance\n",
    "                    \"road_conditions\": random.choice([\"GOOD\", \"FAIR\", \"POOR\", \"HAZARDOUS\"]),\n",
    "                    \"data_source\": \"WEATHER_SERVICE_API\",\n",
    "                    \"last_updated\": datetime.now(timezone.utc).isoformat()\n",
    "                }\n",
    "                \n",
    "                weather_records.append(weather_record)\n",
    "        \n",
    "        df = pd.DataFrame(weather_records)\n",
    "        output_file = self.output_dir / \"batch\" / \"weather_data.parquet\"\n",
    "        df.to_parquet(output_file, index=False)\n",
    "        print(f\"Weather data saved to {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    def generate_route_performance(self, count=500000):\n",
    "        \"\"\"Generate historical route performance data\"\"\"\n",
    "        print(f\"Generating {count:,} route performance records...\")\n",
    "        \n",
    "        performance_records = []\n",
    "        routes = self.routes_df.to_dict('records')\n",
    "        vehicles = self.vehicles_df.to_dict('records')\n",
    "        \n",
    "        for i in range(count):\n",
    "            route = random.choice(routes)\n",
    "            vehicle = random.choice(vehicles)\n",
    "            date = fake.date_between(start_date=\"-1y\", end_date=\"today\")\n",
    "            \n",
    "            # Simulate realistic performance variations\n",
    "            base_duration = route[\"estimated_duration_hours\"]\n",
    "            actual_duration = base_duration * random.uniform(0.8, 1.4)\n",
    "            \n",
    "            performance = {\n",
    "                \"performance_id\": f\"PERF{str(i).zfill(8)}\",\n",
    "                \"route_id\": route[\"route_id\"],\n",
    "                \"vehicle_id\": vehicle[\"vehicle_id\"],\n",
    "                \"driver_id\": vehicle[\"driver_id\"],\n",
    "                \"trip_date\": date.isoformat(),\n",
    "                \"departure_time\": fake.time(),\n",
    "                \"arrival_time\": fake.time(),\n",
    "                \"planned_duration_hours\": base_duration,\n",
    "                \"actual_duration_hours\": round(actual_duration, 2),\n",
    "                \"planned_distance_km\": route[\"distance_km\"],\n",
    "                \"actual_distance_km\": round(route[\"distance_km\"] * random.uniform(0.95, 1.1), 1),\n",
    "                \"fuel_consumed_liters\": round(route[\"distance_km\"] * random.uniform(0.2, 0.5), 2),\n",
    "                \"fuel_cost\": round(route[\"distance_km\"] * random.uniform(0.15, 0.35), 2),\n",
    "                \"packages_delivered\": random.randint(50, 500),\n",
    "                \"delivery_stops\": random.randint(15, 100),\n",
    "                \"on_time_deliveries\": 0,  # Will calculate\n",
    "                \"failed_deliveries\": random.randint(0, 5),\n",
    "                \"average_stop_time_minutes\": round(random.uniform(3, 12), 1),\n",
    "                \"traffic_delay_minutes\": random.randint(0, 120),\n",
    "                \"weather_delay_minutes\": random.randint(0, 60),\n",
    "                \"mechanical_delay_minutes\": random.randint(0, 30),\n",
    "                \"driver_rating\": round(random.uniform(3.5, 5.0), 1),\n",
    "                \"customer_complaints\": random.randint(0, 3),\n",
    "                \"route_efficiency_score\": round(random.uniform(0.7, 0.98), 3),\n",
    "                \"carbon_emissions_kg\": round(route[\"distance_km\"] * random.uniform(0.1, 0.3), 2),\n",
    "                \"cost_per_km\": round(random.uniform(0.8, 2.2), 2),\n",
    "                \"revenue_generated\": round(random.uniform(200, 2000), 2),\n",
    "                \"profit_margin\": round(random.uniform(0.05, 0.25), 3)\n",
    "            }\n",
    "            \n",
    "            # Calculate on-time deliveries\n",
    "            performance[\"on_time_deliveries\"] = max(0, \n",
    "                performance[\"packages_delivered\"] - performance[\"failed_deliveries\"] - random.randint(0, 10)\n",
    "            )\n",
    "            \n",
    "            performance_records.append(performance)\n",
    "            \n",
    "            if i % 25000 == 0 and i > 0:\n",
    "                print(f\"Generated {i:,} route performance records...\")\n",
    "        \n",
    "        df = pd.DataFrame(performance_records)\n",
    "        output_file = self.output_dir / \"batch\" / \"route_performance.parquet\"\n",
    "        df.to_parquet(output_file, index=False)\n",
    "        print(f\"Route performance data saved to {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    def save_reference_data(self):\n",
    "        \"\"\"Save all reference/dimension tables as Parquet files\"\"\"\n",
    "        print(\"Saving reference data tables...\")\n",
    "        \n",
    "        # Save facilities\n",
    "        facilities_file = self.output_dir / \"reference\" / \"facilities.parquet\"\n",
    "        self.facilities_df.to_parquet(facilities_file, index=False)\n",
    "        print(f\"Facilities saved to {facilities_file}\")\n",
    "        \n",
    "        # Save customers\n",
    "        customers_file = self.output_dir / \"reference\" / \"customers.parquet\"\n",
    "        self.customers_df.to_parquet(customers_file, index=False)\n",
    "        print(f\"Customers saved to {customers_file}\")\n",
    "        \n",
    "        # Save vehicles\n",
    "        vehicles_file = self.output_dir / \"reference\" / \"vehicles.parquet\"\n",
    "        self.vehicles_df.to_parquet(vehicles_file, index=False)\n",
    "        print(f\"Vehicles saved to {vehicles_file}\")\n",
    "        \n",
    "        # Save routes\n",
    "        routes_file = self.output_dir / \"reference\" / \"routes.parquet\"\n",
    "        self.routes_df.to_parquet(routes_file, index=False)\n",
    "        print(f\"Routes saved to {routes_file}\")\n",
    "        \n",
    "        # Generate and save additional lookup tables\n",
    "        self._generate_lookup_tables()\n",
    "    \n",
    "    def _generate_lookup_tables(self):\n",
    "        \"\"\"Generate additional lookup/reference tables\"\"\"\n",
    "        \n",
    "        # Service Level Agreements\n",
    "        sla_data = []\n",
    "        for service in self.SERVICE_TYPES:\n",
    "            sla = {\n",
    "                \"service_type\": service,\n",
    "                \"delivery_commitment_days\": 1 if service == \"SAME_DAY\" else (2 if service == \"EXPRESS\" else (3 if service == \"STANDARD\" else 7)),\n",
    "                \"sla_threshold_hours\": 24 if service == \"SAME_DAY\" else (48 if service == \"EXPRESS\" else (72 if service == \"STANDARD\" else 168)),\n",
    "                \"price_per_kg\": round(random.uniform(5, 25), 2),\n",
    "                \"insurance_included\": service in [\"EXPRESS\", \"SAME_DAY\"],\n",
    "                \"tracking_updates_frequency_minutes\": 15 if service == \"SAME_DAY\" else (30 if service == \"EXPRESS\" else 60),\n",
    "                \"refund_policy\": \"FULL_REFUND\" if service == \"SAME_DAY\" else (\"50_PERCENT\" if service == \"EXPRESS\" else \"CREDIT\"),\n",
    "                \"is_active\": True,\n",
    "                \"last_updated\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "            sla_data.append(sla)\n",
    "        \n",
    "        sla_df = pd.DataFrame(sla_data)\n",
    "        sla_file = self.output_dir / \"reference\" / \"service_agreements.parquet\"\n",
    "        sla_df.to_parquet(sla_file, index=False)\n",
    "        print(f\"Service agreements saved to {sla_file}\")\n",
    "        \n",
    "        # Geographic regions and postal codes\n",
    "        postal_zones = []\n",
    "        for i in range(10000):\n",
    "            zone = {\n",
    "                \"postal_code\": fake.postcode(),\n",
    "                \"city\": fake.city(),\n",
    "                \"state_province\": fake.state(),\n",
    "                \"country\": fake.country(),\n",
    "                \"region\": random.choice(self.REGIONS),\n",
    "                \"delivery_zone\": random.choice([\"URBAN\", \"SUBURBAN\", \"RURAL\", \"REMOTE\"]),\n",
    "                \"average_delivery_time_hours\": random.randint(2, 48),\n",
    "                \"special_instructions\": random.choice([None, \"GATED_COMMUNITY\", \"APARTMENT_COMPLEX\", \"BUSINESS_DISTRICT\", \"RESTRICTED_ACCESS\"]),\n",
    "                \"is_serviceable\": random.choice([True] * 95 + [False] * 5),\n",
    "                \"last_updated\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "            postal_zones.append(zone)\n",
    "        \n",
    "        postal_df = pd.DataFrame(postal_zones)\n",
    "        postal_file = self.output_dir / \"reference\" / \"postal_zones.parquet\"\n",
    "        postal_df.to_parquet(postal_file, index=False)\n",
    "        print(f\"Postal zones saved to {postal_file}\")\n",
    "\n",
    "    def generate_all_datasets(self):\n",
    "        \"\"\"Generate complete dataset suite for workshop\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"GENERATING COMPLETE GLOBALSHIP LOGISTICS WORKSHOP DATASETS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Generate reference data\n",
    "        print(\"\\n1. Saving Reference Data...\")\n",
    "        self.save_reference_data()\n",
    "        \n",
    "        # Generate batch datasets\n",
    "        print(\"\\n2. Generating Batch Datasets...\")\n",
    "        self.generate_historical_packages(500000)  # Reduced for workshop\n",
    "        self.generate_weather_data(365)\n",
    "        self.generate_route_performance(100000)  # Reduced for workshop\n",
    "        \n",
    "        # Generate streaming datasets (shorter duration for workshop)\n",
    "        print(\"\\n3. Generating Streaming Datasets...\")\n",
    "        \n",
    "        # Start streaming data generation in parallel threads\n",
    "        def stream_package_scans():\n",
    "            self.generate_package_scans_stream(duration_minutes=10, events_per_second=50)\n",
    "        \n",
    "        def stream_vehicle_telemetry():\n",
    "            self.generate_vehicle_telemetry_stream(duration_minutes=10, events_per_second=25)\n",
    "        \n",
    "        def stream_facility_events():\n",
    "            self.generate_facility_events_stream(duration_minutes=10, events_per_second=15)\n",
    "        \n",
    "        # Start all streaming generators\n",
    "        threads = [\n",
    "            threading.Thread(target=stream_package_scans),\n",
    "            threading.Thread(target=stream_vehicle_telemetry),\n",
    "            threading.Thread(target=stream_facility_events)\n",
    "        ]\n",
    "        \n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        \n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "        print(\"\\n4. Generating Additional Files...\")\n",
    "        self._generate_config_files()\n",
    "        self._generate_sample_queries()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"DATASET GENERATION COMPLETE!\")\n",
    "        print(\"=\" * 80)\n",
    "        self._print_dataset_summary()\n",
    "    \n",
    "    def _generate_config_files(self):\n",
    "        \"\"\"Generate configuration and schema files\"\"\"\n",
    "        \n",
    "        # Data source configuration\n",
    "        config = {\n",
    "            \"streaming_sources\": {\n",
    "                \"package_scans\": {\n",
    "                    \"format\": \"json\",\n",
    "                    \"schema_evolution\": True,\n",
    "                    \"checkpoint_location\": \"/mnt/checkpoints/package_scans\",\n",
    "                    \"trigger\": \"10 seconds\",\n",
    "                    \"watermark\": \"scan_timestamp\"\n",
    "                },\n",
    "                \"vehicle_telemetry\": {\n",
    "                    \"format\": \"json\", \n",
    "                    \"schema_evolution\": True,\n",
    "                    \"checkpoint_location\": \"/mnt/checkpoints/vehicle_telemetry\",\n",
    "                    \"trigger\": \"30 seconds\",\n",
    "                    \"watermark\": \"timestamp\"\n",
    "                },\n",
    "                \"facility_events\": {\n",
    "                    \"format\": \"json\",\n",
    "                    \"schema_evolution\": True, \n",
    "                    \"checkpoint_location\": \"/mnt/checkpoints/facility_events\",\n",
    "                    \"trigger\": \"1 minute\",\n",
    "                    \"watermark\": \"timestamp\"\n",
    "                }\n",
    "            },\n",
    "            \"batch_sources\": {\n",
    "                \"historical_packages\": {\n",
    "                    \"format\": \"parquet\",\n",
    "                    \"partitioned_by\": [\"ship_date\"],\n",
    "                    \"update_frequency\": \"daily\"\n",
    "                },\n",
    "                \"weather_data\": {\n",
    "                    \"format\": \"parquet\", \n",
    "                    \"partitioned_by\": [\"date\", \"facility_id\"],\n",
    "                    \"update_frequency\": \"hourly\"\n",
    "                },\n",
    "                \"route_performance\": {\n",
    "                    \"format\": \"parquet\",\n",
    "                    \"partitioned_by\": [\"trip_date\"],\n",
    "                    \"update_frequency\": \"daily\"\n",
    "                }\n",
    "            },\n",
    "            \"reference_data\": {\n",
    "                \"facilities\": {\"format\": \"parquet\", \"update_frequency\": \"weekly\"},\n",
    "                \"customers\": {\"format\": \"parquet\", \"update_frequency\": \"daily\"},\n",
    "                \"vehicles\": {\"format\": \"parquet\", \"update_frequency\": \"monthly\"},\n",
    "                \"routes\": {\"format\": \"parquet\", \"update_frequency\": \"weekly\"}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        config_file = self.output_dir / \"config\" / \"data_sources.json\"\n",
    "        config_file.parent.mkdir(exist_ok=True)\n",
    "        with open(config_file, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        print(f\"Configuration saved to {config_file}\")\n",
    "    \n",
    "    def _generate_sample_queries(self):\n",
    "        \"\"\"Generate sample SQL queries for workshop\"\"\"\n",
    "        \n",
    "        queries = {\n",
    "            \"real_time_dashboard\": \"\"\"\n",
    "-- Real-time Package Volume Dashboard\n",
    "SELECT \n",
    "    facility_code,\n",
    "    facility_name,\n",
    "    COUNT(*) as packages_scanned_last_hour,\n",
    "    COUNT(CASE WHEN scan_event = 'DELIVERED' THEN 1 END) as deliveries_completed,\n",
    "    COUNT(CASE WHEN scan_event = 'EXCEPTION' THEN 1 END) as exceptions,\n",
    "    AVG(CASE WHEN scan_event = 'DELIVERED' THEN \n",
    "        DATEDIFF(scan_timestamp, ship_timestamp) END) as avg_delivery_days\n",
    "FROM package_scans_stream\n",
    "WHERE scan_timestamp >= current_timestamp() - INTERVAL 1 HOUR\n",
    "GROUP BY facility_code, facility_name\n",
    "ORDER BY packages_scanned_last_hour DESC;\n",
    "            \"\"\",\n",
    "            \n",
    "            \"delivery_performance\": \"\"\"\n",
    "-- Service Level Agreement Performance\n",
    "WITH delivery_performance AS (\n",
    "    SELECT \n",
    "        service_type,\n",
    "        COUNT(*) as total_packages,\n",
    "        COUNT(CASE WHEN actual_delivery_date <= promised_delivery_date THEN 1 END) as on_time_deliveries,\n",
    "        AVG(DATEDIFF(actual_delivery_date, ship_date)) as avg_delivery_days,\n",
    "        AVG(shipping_cost) as avg_revenue_per_package\n",
    "    FROM historical_packages\n",
    "    WHERE ship_date >= current_date() - INTERVAL 30 DAYS\n",
    "    GROUP BY service_type\n",
    ")\n",
    "SELECT \n",
    "    service_type,\n",
    "    total_packages,\n",
    "    on_time_deliveries,\n",
    "    ROUND((on_time_deliveries * 100.0 / total_packages), 2) as on_time_percentage,\n",
    "    avg_delivery_days,\n",
    "    avg_revenue_per_package\n",
    "FROM delivery_performance\n",
    "ORDER BY on_time_percentage DESC;\n",
    "            \"\"\",\n",
    "            \n",
    "            \"route_optimization\": \"\"\"\n",
    "-- Route Efficiency Analysis\n",
    "SELECT \n",
    "    r.route_id,\n",
    "    r.origin_facility_code,\n",
    "    r.destination_facility_code,\n",
    "    r.distance_km,\n",
    "    AVG(rp.actual_duration_hours) as avg_actual_duration,\n",
    "    r.estimated_duration_hours,\n",
    "    AVG(rp.fuel_consumed_liters) as avg_fuel_consumption,\n",
    "    AVG(rp.packages_delivered) as avg_packages_per_trip,\n",
    "    COUNT(rp.performance_id) as total_trips_last_month,\n",
    "    AVG(rp.route_efficiency_score) as avg_efficiency_score\n",
    "FROM routes r\n",
    "JOIN route_performance rp ON r.route_id = rp.route_id\n",
    "WHERE rp.trip_date >= current_date() - INTERVAL 30 DAYS\n",
    "GROUP BY r.route_id, r.origin_facility_code, r.destination_facility_code, \n",
    "         r.distance_km, r.estimated_duration_hours\n",
    "HAVING total_trips_last_month >= 10\n",
    "ORDER BY avg_efficiency_score DESC;\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "        queries_file = self.output_dir / \"config\" / \"sample_queries.sql\"\n",
    "        queries_file.parent.mkdir(exist_ok=True)\n",
    "        with open(queries_file, 'w') as f:\n",
    "            for name, query in queries.items():\n",
    "                f.write(f\"-- {name.upper()}\\n{query}\\n\\n\")\n",
    "        \n",
    "        print(f\"Sample queries saved to {queries_file}\")\n",
    "    \n",
    "    def _print_dataset_summary(self):\n",
    "        \"\"\"Print summary of generated datasets\"\"\"\n",
    "        print(\"\\nDATASET SUMMARY:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Count files and sizes\n",
    "        total_files = 0\n",
    "        total_size = 0\n",
    "        \n",
    "        for subdir in [\"streaming\", \"batch\", \"reference\", \"config\"]:\n",
    "            subdir_path = self.output_dir / subdir\n",
    "            if subdir_path.exists():\n",
    "                files = list(subdir_path.rglob(\"*\"))\n",
    "                files = [f for f in files if f.is_file()]\n",
    "                subdir_size = sum(f.stat().st_size for f in files)\n",
    "                \n",
    "                print(f\"{subdir.upper()}:\")\n",
    "                for file in files:\n",
    "                    size_mb = file.stat().st_size / (1024 * 1024)\n",
    "                    print(f\"  - {file.name}: {size_mb:.1f} MB\")\n",
    "                \n",
    "                total_files += len(files)\n",
    "                total_size += subdir_size\n",
    "        \n",
    "        print(f\"\\nTOTAL: {total_files} files, {total_size / (1024 * 1024):.1f} MB\")\n",
    "        print(f\"Output directory: {self.output_dir.absolute()}\")\n",
    "        \n",
    "        print(f\"\\nREFERENCE DATA COUNTS:\")\n",
    "        print(f\"  - Facilities: {len(self.facilities_df):,}\")\n",
    "        print(f\"  - Customers: {len(self.customers_df):,}\")\n",
    "        print(f\"  - Vehicles: {len(self.vehicles_df):,}\")\n",
    "        print(f\"  - Routes: {len(self.routes_df):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e8a0c2e-694d-411d-94be-4936a37cdb36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main(volume_path=None):\n",
    "    \"\"\"Main function to generate all workshop datasets\n",
    "    \n",
    "    Args:\n",
    "        volume_path (str, optional): Path to Databricks Unity Catalog volume \n",
    "                                   (e.g., \"/Volumes/catalog/schema/volume_name/workshop_data\")\n",
    "                                   If None, uses local path \"globalship_workshop_data\"\n",
    "    \"\"\"\n",
    "    print(\"GlobalShip Logistics Data Generator\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Set output directory - use volume path if provided, otherwise local path\n",
    "    if volume_path:\n",
    "        output_dir = volume_path\n",
    "        print(f\"Using Databricks Volume path: {output_dir}\")\n",
    "    else:\n",
    "        output_dir = \"globalship_workshop_data\"\n",
    "        print(f\"Using local path: {output_dir}\")\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = LogisticsDataGenerator(output_dir)\n",
    "    \n",
    "    # Generate all datasets\n",
    "    generator.generate_all_datasets()\n",
    "    \n",
    "    print(\"\\nWorkshop datasets are ready!\")\n",
    "    if volume_path:\n",
    "        print(f\"Datasets are available in Databricks Volume: {volume_path}\")\n",
    "    else:\n",
    "        print(\"You can now use these datasets with Databricks for the capstone project.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9f0b44a-66b2-40e0-9ef3-ecb7f486a0e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalShip Logistics Data Generator\n==================================================\nUsing Databricks Volume path: /Volumes/workspace/default/sample_data\nInitialized LogisticsDataGenerator with output directory: /Volumes/workspace/default/sample_data\n================================================================================\nGENERATING COMPLETE GLOBALSHIP LOGISTICS WORKSHOP DATASETS\n================================================================================\n\n1. Saving Reference Data...\nSaving reference data tables...\nFacilities saved to /Volumes/workspace/default/sample_data/reference/facilities.parquet\nCustomers saved to /Volumes/workspace/default/sample_data/reference/customers.parquet\nVehicles saved to /Volumes/workspace/default/sample_data/reference/vehicles.parquet\nRoutes saved to /Volumes/workspace/default/sample_data/reference/routes.parquet\nService agreements saved to /Volumes/workspace/default/sample_data/reference/service_agreements.parquet\nPostal zones saved to /Volumes/workspace/default/sample_data/reference/postal_zones.parquet\n\n2. Generating Batch Datasets...\nGenerating 500,000 historical packages...\nGenerated 50,000 historical packages...\nGenerated 100,000 historical packages...\nGenerated 150,000 historical packages...\nGenerated 200,000 historical packages...\nGenerated 250,000 historical packages...\nGenerated 300,000 historical packages...\nGenerated 350,000 historical packages...\nGenerated 400,000 historical packages...\nGenerated 450,000 historical packages...\nHistorical packages saved to /Volumes/workspace/default/sample_data/batch/historical_packages.parquet\nGenerating weather data for 365 days...\nWeather data saved to /Volumes/workspace/default/sample_data/batch/weather_data.parquet\nGenerating 100,000 route performance records...\nGenerated 25,000 route performance records...\nGenerated 50,000 route performance records...\nGenerated 75,000 route performance records...\nRoute performance data saved to /Volumes/workspace/default/sample_data/batch/route_performance.parquet\n\n3. Generating Streaming Datasets...\nGenerating package scan stream for 10 minutes at 50 events/second...\nGenerating vehicle telemetry stream for 10 minutes at 25 events/second...\nGenerating facility events stream for 10 minutes at 15 events/second...\nGenerated 5,000 vehicle telemetry events...\nGenerated 6,000 facility events...\nGenerated 10,000 vehicle telemetry events...\nPackage scan stream generation complete. Generated 28,874 events.\nFacility events stream generation complete. Generated 8,955 events.\nVehicle telemetry stream generation complete. Generated 12,850 events.\n\n4. Generating Additional Files...\nConfiguration saved to /Volumes/workspace/default/sample_data/config/data_sources.json\nSample queries saved to /Volumes/workspace/default/sample_data/config/sample_queries.sql\n\n================================================================================\nDATASET GENERATION COMPLETE!\n================================================================================\n\nDATASET SUMMARY:\n--------------------------------------------------\nSTREAMING:\n  - facility_events.jsonl: 2.7 MB\n  - package_scans.jsonl: 20.9 MB\n  - vehicle_telemetry.jsonl: 13.9 MB\nBATCH:\n  - historical_packages.parquet: 64.8 MB\n  - route_performance.parquet: 6.9 MB\n  - weather_data.parquet: 28.6 MB\nREFERENCE:\n  - customers.parquet: 11.6 MB\n  - facilities.parquet: 0.6 MB\n  - postal_zones.parquet: 0.3 MB\n  - routes.parquet: 1.5 MB\n  - service_agreements.parquet: 0.0 MB\n  - vehicles.parquet: 15.5 MB\nCONFIG:\n  - data_sources.json: 0.0 MB\n  - sample_queries.sql: 0.0 MB\n\nTOTAL: 14 files, 167.3 MB\nOutput directory: /Volumes/workspace/default/sample_data\n\nREFERENCE DATA COUNTS:\n  - Facilities: 5,000\n  - Customers: 100,000\n  - Vehicles: 180,000\n  - Routes: 50,000\n\nWorkshop datasets are ready!\nDatasets are available in Databricks Volume: /Volumes/workspace/default/sample_data\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Volumes/workspace/default/sample_data\"\n",
    "main(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61a644b9-6688-44bf-a2a7-c7be174d8541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcfcb7d3-d4cc-4342-b1ad-faccef54520d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33e662d-761b-41cc-9037-26f45840b904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Gen",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}